{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction of policies, outcomes and correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code allows the extraction of policies, their outcomes and the correlations between them.\n",
    "\n",
    "It uses gpt-4o-mini from the OpenAI library. \n",
    "gpt-4o-mini, is a compact yet high-performance Large Language Model (LLM) developed by OpenAI. While GPT-4o-mini is not open-source, and its development and training processes lack transparency due to restricted access via OpenAIâ€™s servers, its performance has been demonstrated to surpass other models.\n",
    "\n",
    "In this Jupyter Notebook we will: \n",
    "1. Import the data retrieved from the screening process ; \n",
    "2. Import the relevant packages ;\n",
    "3. Extract policies, outcomes and correlations with gpt-4o-mini ;\n",
    "4. Export the data. \n",
    "\n",
    "To complete those tasks you will need:\n",
    "- A dataset of screened papers relevant to your research question (db_init) ; \n",
    "- A OpenAi account. \n",
    "\n",
    "At the end of this script you will extract: \n",
    "- The db_init dataset with a JSON format column containing the extracted policies, outcomes and correlations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the data retrieved from the screening process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the input and output access paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input path of the dataset of screened papers relevant to your research question (db_init)\n",
    "input_path = \"\"\n",
    "## Output path \n",
    "output_path  = \"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_init = pd.read_csv(input_path)\n",
    "db_init[\"abstract\"] = db_init[\"abstract\"].fillna(\"\").astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract random sample for testing\n",
    "random_rows = db_init.sample(n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import the relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your API key for OpenAI. \n",
    "import openai\n",
    "openai.organization = \"\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract policies, outcomes and correlations with gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import RateLimitError\n",
    "import time  # Make sure you import time for retry delays\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract features and their correlations\n",
    "def extract_features_and_correlations(text, model=\"gpt-4o-mini\"):\n",
    "    prompt = f\"\"\" \n",
    "    Define the following key variables for the extraction process: \n",
    "    \n",
    "    1. **GEOGRAPHIC**: The **GEOGRAPHIC** refers to the **geographical scope** or **area of study** under study.  \n",
    "    - If the abstract mentions a specific region, **country**, or **city** such as **deprived neighbourhoods**, specific **countries**, or **cities**, specify this. \n",
    "    - If no geographical scope is mentioned, label it as \"None\". \n",
    "    \n",
    "    2. **ITEM**: The specific practice, choice, lifestyle, public policy, private action, property, feature, technological device, system, or service mentioned in the abstract.  \n",
    "    **ITEM** cannot be a metric, measure, methods, or model. It refers to concrete actions, policies, features, or devices described in the text. \n",
    "    It should include the sense of variation of the **ITEM** (**increasing**, **lower**, **diminish**, etc.).  \n",
    "    The **ITEM** should be complete and as detailed as possible, extracting all relevant aspects from the abstract (for instance, if the abstract analyses the \"European regulation\" **ITEM** must report on what it applies (example: transport safety), if etc.). \n",
    "    \n",
    "    **Examples of ITEM**: \n",
    "    - **Practices, choices, behaviors, and lifestyles**: biking, carpooling, car-free lifestyle, teleworking. \n",
    "    - **Public policies or private actions**: carbon tax, transit infrastructure investment, reduced traffic zoning, corporate mobility plan, car weight reduction. \n",
    "    - **Properties and features of the built environment and cities**: sidewalks width, bike lanes investment, urban density, walkability, infrastructure. \n",
    "    - **Spatial distribution of urban amenities and location mismatches**: spatial mismatch, job accessibility, home-work separation, urban growth, sprawling development, residential specialization. \n",
    "    - **Technical or technological devices, systems, and services**: electric scooter sharing, bus rapid transit, microcars, trolleybus, tram systems. \n",
    "\n",
    "    3. **FACTOR**: The **FACTOR** refers to the specific outcome or characteristic that the **ITEM** impacts or influences. This could be a variable, metric, or property, such as CO2 emissions, energy use, health outcomes, traffic congestion, car dependency, food or job accessibility, income inequalities, or land use.  \n",
    "    - **FACTOR** cannot include negative formulations like \"decrease\", \"reduction\", \"lowering\", \"savings\", or \"loss of\". If the **FACTOR** is presented negatively in the abstract, it should be rephrased positively (e.g., \"CO2 emission reduction\" should be framed as \"CO2 emissions\", the reduction part would be included in the **CORRELATION**). \n",
    "    - **FACTOR** can also be an **ITEM** in the context of other **ITEMs**. In other words, an **ITEM** can act as a **FACTOR** for another **ITEM** if it influences or affects it. For example, **public transport** (an **ITEM**) can affect **CO2 emissions** (a **FACTOR**), but **CO2 emissions** can also be impacted by another **ITEM** like **carpooling**. Therefore, when extracting **ITEMs** and **FACTORS**, be aware that **ITEMs** can also act as **FACTORS** for other **ITEMs**. \n",
    "\n",
    "    4. **CORRELATION**: The **CORRELATION** describes the nature of the relationship between the **ITEM** and the **FACTOR**: \n",
    "    - If the **ITEM** is **increasing** or **raising** the **FACTOR**, label it as \"increasing\". \n",
    "    - If the **ITEM** is **reducing**, **diminishing**, or **lowering** the **FACTOR**, label it as \"decreasing\". \n",
    "    - If the **ITEM** has a **neutral impact** on the **FACTOR**, label it as \"neutral\". \n",
    "    - If the **ITEM** has an **unspecified** effect, label it as \"None\". \n",
    "\n",
    "    5. **POPULATION**: The **POPULATION** refers to the specific **socio-demographic group** affected by the **FACTOR**.   \n",
    "    - If the abstract mentions a specific socio-demographic group, such as people in **elderly**, **young**, **low-income households**, **first decile**, **suburban households**, **peripheral**, etc., specify this. \n",
    "    - If no socio-demographic group is mentioned, label it as \"None\". \n",
    "\n",
    "    6. **MODE**: The **MODE** refers to the specific modes of transportation related to the **ITEM** and mentioned in the abstract.   \n",
    "    - If the abstract mentions transportation modes, such as **bus**, **car**, **bike**, **bike-sharing**, **public transport**, **electric scooter**, **automobile**, etc., please specify it. \n",
    "    - If no **mode of transport** is **clearly** mentioned, leave it as \"None\". \n",
    "\n",
    "    7. **ACTOR**: The **ACTOR** refers to the institution or person directly effecting the **ITEM** and mentioned in the abstract.  \n",
    "    - If the abstract mentions, such as **government**, **local authority**, **car manufacturer**, **firm**, **individual** etc., please specify it.  \n",
    "    - If no actor is **clearly** mentioned, leave it as \"None\".  \n",
    "\n",
    "    --- \n",
    "\n",
    "    Now, analyze the following abstract and: \n",
    "    1. Identify the **GEOGRAPHIC** scope of the study (if mentioned in the abstract). If not, label it as \"None\". \n",
    "    2. Extract all the **ITEMs** mentioned. If **no ITEMs** are found in the abstract, return **None** and stop the prompt. \n",
    "    3. For each extracted **ITEM**, determine whether it has a **increasing**, **decreasing**, or **neutral** effect on one or more **FACTORS**. Extract the impacted **FACTORS** (write \"None\" if no factors are impacted). \n",
    "    4. For each **ITEM** and its associated **FACTOR**, specify the **CORRELATION** as stated in the abstract.  \n",
    "    5. If the **FACTOR** applies to a specific **POPULATION**, specify it as **POPULATION**. \n",
    "    6. If the **ITEM** is related to a specific **MODE** of transportation, specify it. \n",
    "    7. If the **ITEM** is related to a specific **ACTOR**, specify it. \n",
    "\n",
    "    **Do not make any assumptions or infer data for items that are not mentioned in the abstract.** \n",
    "    **Do not use acronyms if the developped formulation is in the abstract.** \n",
    "\n",
    "    Return the extracted information in the following JSON format: \n",
    "\n",
    "    {{ \n",
    "        \"GEOGRAPHIC\": \"new towns\", \n",
    "        \"transit infrastructure investment\": {{ \n",
    "            \"ACTOR\": \"urban planner\", \n",
    "            \"MODE\": \"None\", \n",
    "            \"POPULATION\": \"None\", \n",
    "            \"FACTOR\": {{ \n",
    "                \"social exclusion\": {{ \n",
    "                    \"CORRELATION\": \"decreasing\", \n",
    "                }}, \n",
    "                \"CO2 emissions\": {{ \n",
    "                    \"CORRELATION\": \"decreasing\", \n",
    "                }} \n",
    "            }} \n",
    "        }}, \n",
    "        \"microcars\": {{ \n",
    "            \"ACTOR\": \"car manufacturer\", \n",
    "            \"MODE\": \"car\", \n",
    "            \"POPULATION\": \"elderly\", \n",
    "            \"FACTOR\": {{ \n",
    "                \"materials use\": {{ \n",
    "                    \"CORRELATION\": \"decreasing\", \n",
    "                }}, \n",
    "                \"food accessibility\": {{ \n",
    "                    \"CORRELATION\": \"increasing\", \n",
    "                }} \n",
    "            }} \n",
    "        }}, \n",
    "        ... \n",
    "    }} \n",
    "\n",
    "\n",
    "    **The above labels are only examples of the data format. Do **not** include them in your response. The extracted data should use the actual **ITEM** and **FACTOR** names as they appear in the abstract.** \n",
    "\n",
    "    The output should **not** start with the word \"json\" or include any other labels outside of the JSON format. \n",
    "\n",
    "    Abstract: {text} \n",
    "\n",
    "    \"\"\" \n",
    "  \n",
    "    retry_attempts = 5\n",
    "    retry_delay = 2  # seconds\n",
    "\n",
    "    for attempt in range(retry_attempts):\n",
    "        try:\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "            )\n",
    "            extracted_data = response.choices[0].message.content.strip()\n",
    "            return extracted_data\n",
    "        except RateLimitError as e:\n",
    "            if attempt < retry_attempts - 1:\n",
    "                print(f\"Rate limit hit. Retrying in {retry_delay} seconds...\")\n",
    "                time.sleep(retry_delay)\n",
    "                retry_delay *= 2  # Exponential backoff\n",
    "            else:\n",
    "                print(f\"Failed after {retry_attempts} attempts: {e}\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing abstract: {e}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a single abstract\n",
    "def process_abstract(abstract):\n",
    "    if not abstract.strip():\n",
    "        return \"No abstract\"\n",
    "    else:\n",
    "        return extract_features_and_correlations(abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch processing function\n",
    "def process_in_batches(df, batch_size=10):\n",
    "    results = []\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i + batch_size]\n",
    "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "            batch_results = list(executor.map(process_abstract, batch['abstract']))\n",
    "        results.extend(batch_results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db_init\n",
    "\n",
    "# Run the batch processing\n",
    "df['extracted_features_and_correlations'] = process_in_batches(df, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Export the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the updated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated dataset\n",
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
